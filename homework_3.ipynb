{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85111cb2-7b4a-4333-b06e-c701e6034157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5038b6ab-6824-4260-a17d-59efbd4dfa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41122221-a995-4c20-9065-213e37725d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-13 13:31:16--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80876 (79K) [text/plain]\n",
      "Saving to: ‘course_lead_scoring.csv’\n",
      "\n",
      "course_lead_scoring 100%[===================>]  78.98K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2025-10-13 13:31:16 (30.1 MB/s) - ‘course_lead_scoring.csv’ saved [80876/80876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget $data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f1d934-d08b-41ae-a835-897d362a6df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('course_lead_scoring.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d093226-2440-4e5e-a137-3c12b8fc855e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1462, 9)\n",
      "\n",
      "Checking for missing values:\n",
      "\n",
      "lead_source                 128\n",
      "industry                    134\n",
      "number_of_courses_viewed      0\n",
      "annual_income               181\n",
      "employment_status           100\n",
      "location                     63\n",
      "interaction_count             0\n",
      "lead_score                    0\n",
      "converted                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display basic info\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nChecking for missing values:\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c52de1e1-2d49-4005-a702-a741c82035e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after imputation:\n",
      "\n",
      "lead_source                 0\n",
      "industry                    0\n",
      "number_of_courses_viewed    0\n",
      "annual_income               0\n",
      "employment_status           0\n",
      "location                    0\n",
      "interaction_count           0\n",
      "lead_score                  0\n",
      "converted                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().sum() > 0:  # Only handle if there are missing values\n",
    "        if df[col].dtype == 'object':  # Categorical features\n",
    "            df[col] = df[col].fillna('NA')\n",
    "        else:  # Numerical features\n",
    "            df[col] = df[col].fillna(0.0)\n",
    "\n",
    "# to verify no missing values remain\n",
    "print(\"\\nMissing values after imputation:\\n\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00648487-6477-497e-879a-9c588a56c3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    retail\n",
       "Name: industry, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.industry.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "697e1178-cee0-4060-bd77-ca4f1c20da42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "                           number_of_courses_viewed  annual_income  \\\n",
      "number_of_courses_viewed                  1.000000       0.009770   \n",
      "annual_income                             0.009770       1.000000   \n",
      "interaction_count                        -0.023565       0.027036   \n",
      "lead_score                               -0.004879       0.015610   \n",
      "converted                                 0.435914       0.053131   \n",
      "\n",
      "                          interaction_count  lead_score  converted  \n",
      "number_of_courses_viewed          -0.023565   -0.004879   0.435914  \n",
      "annual_income                      0.027036    0.015610   0.053131  \n",
      "interaction_count                  1.000000    0.009888   0.374573  \n",
      "lead_score                         0.009888    1.000000   0.193673  \n",
      "converted                          0.374573    0.193673   1.000000   \n",
      "\n",
      "The two features with the highest correlation are: ('converted', 'number_of_courses_viewed')\n",
      "Correlation coefficient: 0.436\n"
     ]
    }
   ],
   "source": [
    "# Select only numerical features\n",
    "num_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = num_df.corr()\n",
    "\n",
    "# Display correlation matrix\n",
    "print(\"Correlation Matrix:\\n\", corr_matrix, \"\\n\")\n",
    "\n",
    "# Find the two features with the highest correlation (excluding self-correlation)\n",
    "corr_unstacked = corr_matrix.unstack().sort_values(ascending=False)\n",
    "# Drop self-correlations (where correlation == 1)\n",
    "corr_unstacked = corr_unstacked[corr_unstacked < 1]\n",
    "\n",
    "# Get the pair with the highest correlation\n",
    "highest_corr = corr_unstacked.idxmax()\n",
    "max_corr_value = corr_unstacked.max()\n",
    "\n",
    "print(f\"The two features with the highest correlation are: {highest_corr}\")\n",
    "print(f\"Correlation coefficient: {max_corr_value:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bcf3f17-fda8-4863-9f94-4df680cc3cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (877, 8) (877,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Separate target and features\n",
    "y = df['converted']\n",
    "X = df.drop('converted', axis=1)\n",
    "\n",
    "# First split: 60% train, 40% temp (val+test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d20bc4-0460-4618-bb06-858a9a3bc769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set: (292, 8) (292,)\n",
      "Test set: (293, 8) (293,)\n"
     ]
    }
   ],
   "source": [
    "# Second split: 20% val, 20% test (each half of temp)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Print resulting shapes\n",
    "\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a753990-38e1-4a23-b437-0c4f93b819eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1462-877\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "035cb390-cf0f-40b2-8bd7-76407e52514d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "292+293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5922a979-86a2-4665-b483-fb157beb7192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Scores between categorical features and target (y):\n",
      "\n",
      "             Feature  Mutual Information\n",
      "0        lead_source                0.03\n",
      "1           industry                0.02\n",
      "2  employment_status                0.02\n",
      "3           location                0.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# Select categorical columns\n",
    "cat_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Compute Mutual Information for each categorical feature\n",
    "mi_scores = {}\n",
    "for col in cat_features:\n",
    "    mi = mutual_info_score(X_train[col], y_train)\n",
    "    mi_scores[col] = round(mi, 2)\n",
    "\n",
    "# Convert to DataFrame for neat display\n",
    "mi_df = pd.DataFrame(list(mi_scores.items()), columns=['Feature', 'Mutual Information'])\n",
    "mi_df = mi_df.sort_values(by='Mutual Information', ascending=False)\n",
    "\n",
    "print(\"Mutual Information Scores between categorical features and target (y):\\n\")\n",
    "print(mi_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a7c3ef8-121e-4589-abb0-23ca29e672cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy (rounded to 2 decimals): 0.74\n"
     ]
    }
   ],
   "source": [
    "# logistic_regression_pipeline.py\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# One-hot encode categorical variables (use pandas.get_dummies)\n",
    "X_train_enc = pd.get_dummies(X_train, drop_first=False)\n",
    "X_val_enc = pd.get_dummies(X_val, drop_first=False)\n",
    "\n",
    "# Align validation columns to training columns (add missing ones as zeros)\n",
    "X_val_enc = X_val_enc.reindex(columns=X_train_enc.columns, fill_value=0)\n",
    "\n",
    "# Train logistic regression with specified parameters\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_enc, y_train)\n",
    "\n",
    "# Predict on validation set and compute accuracy (rounded to 2 decimals)\n",
    "y_val_pred = model.predict(X_val_enc)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation accuracy (rounded to 2 decimals):\", round(accuracy, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd381b29-5254-40d8-b087-b342d4e3b413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base validation accuracy: 0.7431506849315068\n",
      "\n",
      "Feature elimination results (least useful at the top):\n",
      "                    Feature  Accuracy_without_feature  Accuracy_difference\n",
      "3             annual_income                  0.856164            -0.113014\n",
      "4         employment_status                  0.746575            -0.003425\n",
      "5                  location                  0.743151             0.000000\n",
      "1                  industry                  0.743151             0.000000\n",
      "7                lead_score                  0.743151             0.000000\n",
      "0               lead_source                  0.729452             0.013699\n",
      "2  number_of_courses_viewed                  0.678082             0.065068\n",
      "6         interaction_count                  0.674658             0.068493\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode\n",
    "X_train_enc = pd.get_dummies(X_train, drop_first=False)\n",
    "X_val_enc = pd.get_dummies(X_val, drop_first=False)\n",
    "X_val_enc = X_val_enc.reindex(columns=X_train_enc.columns, fill_value=0)\n",
    "\n",
    "# --- Train base model ---\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_enc, y_train)\n",
    "base_acc = accuracy_score(y_val, model.predict(X_val_enc))\n",
    "\n",
    "# --- Feature elimination test ---\n",
    "results = []\n",
    "for feature in X.columns:\n",
    "    # Drop one feature\n",
    "    X_train_drop = X_train.drop(columns=[feature])\n",
    "    X_val_drop = X_val.drop(columns=[feature])\n",
    "\n",
    "    # One-hot encode again\n",
    "    X_train_drop_enc = pd.get_dummies(X_train_drop, drop_first=False)\n",
    "    X_val_drop_enc = pd.get_dummies(X_val_drop, drop_first=False)\n",
    "    X_val_drop_enc = X_val_drop_enc.reindex(columns=X_train_drop_enc.columns, fill_value=0)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train_drop_enc, y_train)\n",
    "    acc = accuracy_score(y_val, model.predict(X_val_drop_enc))\n",
    "\n",
    "    # Record accuracy difference\n",
    "    diff = base_acc - acc\n",
    "    results.append((feature, acc, diff))\n",
    "\n",
    "# --- Display results ---\n",
    "results_df = pd.DataFrame(results, columns=[\"Feature\", \"Accuracy_without_feature\", \"Accuracy_difference\"])\n",
    "results_df = results_df.sort_values(by=\"Accuracy_difference\", ascending=True)\n",
    "print(\"Base validation accuracy:\", base_acc)\n",
    "print(\"\\nFeature elimination results (least useful at the top):\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf0835cf-767e-4273-a09e-5f71733c914e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results:\n",
      "         C  Validation_Accuracy\n",
      "0    0.01                0.743\n",
      "1    0.10                0.743\n",
      "2    1.00                0.743\n",
      "3   10.00                0.743\n",
      "4  100.00                0.743\n",
      "\n",
      "Best C: 0.01 with accuracy: 0.743\n"
     ]
    }
   ],
   "source": [
    "# Try different values of C\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "results = []\n",
    "\n",
    "for c in C_values:\n",
    "    model = LogisticRegression(solver='liblinear', C=c, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_enc, y_train)\n",
    "    y_pred = model.predict(X_val_enc)\n",
    "    acc = round(accuracy_score(y_val, y_pred), 3)\n",
    "    results.append((c, acc))\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results, columns=['C', 'Validation_Accuracy'])\n",
    "best = results_df.loc[results_df['Validation_Accuracy'].idxmax()]\n",
    "\n",
    "print(\"Validation results:\\n\", results_df)\n",
    "print(\"\\nBest C:\", best['C'], \"with accuracy:\", best['Validation_Accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fb1f2b-4528-418f-a6cf-b898e92189b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
